{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "import pandas as pd\r\n",
    "from glob import glob\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "import seaborn as sns\r\n",
    "import numpy as np\r\n",
    "import torch\r\n",
    "from torchvision import transforms\r\n",
    "from PIL import Image\r\n",
    "from sklearn.model_selection import train_test_split"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "INPUT_data = 'data/'\r\n",
    "INPUT_photo = os.path.join(INPUT_data, 'photos/')\r\n",
    "\r\n",
    "OUTPUT = 'out_put/'\r\n",
    "os.makedirs(OUTPUT, exist_ok=True)\r\n",
    "\r\n",
    "photo_pathes = glob(os.path.join(INPUT_photo, '*.jpg'))\r\n",
    "train_df = pd.read_csv(os.path.join(INPUT_data, 'train.csv'))\r\n",
    "test_df = pd.read_csv(os.path.join(INPUT_data, 'test.csv'))\r\n",
    "\r\n",
    "material_df = pd.read_csv(os.path.join(INPUT_data, 'materials.csv'))\r\n",
    "technique_df = pd.read_csv(os.path.join(INPUT_data, 'techniques.csv'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "##image functions\r\n",
    "def to_img_path(object_id):\r\n",
    "    return os.path.join(INPUT_photo, f'{object_id}.jpg')\r\n",
    "\r\n",
    "def read_image(object_id):\r\n",
    "    return Image.open(to_img_path(object_id))\r\n",
    "\r\n",
    "\r\n",
    "IMG_MEAN = [0.485, 0.456, 0.406]\r\n",
    "IMG_STD = [0.229, 0.224, 0.225]\r\n",
    "\r\n",
    "class art_Dataset(torch.utils.data.Dataset):\r\n",
    "    object_path_key = 'object_path'\r\n",
    "    label_key = 'sorting_date'\r\n",
    "\r\n",
    "    def __init__(self, meta_data, is_train=True):\r\n",
    "        self.meta_data = meta_data\r\n",
    "        self.is_train = is_train\r\n",
    "\r\n",
    "        self.train_data = meta_data.copy()\r\n",
    "        self.train_data['object_path'] = self.train_data['object_id'].map(to_img_path)\r\n",
    "        self.train_data = self.train_data.reset_index(drop=True)\r\n",
    "        self.train_data = self.train_data.to_dict(orient='index')\r\n",
    "        self.transform_train = transforms.ToTensor()\r\n",
    "        self.transform_test = transforms.ToTensor()\r\n",
    "\r\n",
    "    def __getitem__(self, idx):\r\n",
    "        data = self.train_data[idx]\r\n",
    "        obj_path, t_train = data.get(self.object_path_key), data.get(self.label_key, -1)\r\n",
    "        x_data = Image.open(obj_path)\r\n",
    "\r\n",
    "        if self.is_train: \r\n",
    "            x_data = self.transform_train(x_data)\r\n",
    "        else:\r\n",
    "            x_data = self.transform_test(x_data)\r\n",
    "\r\n",
    "        return x_data, t_train\r\n",
    "\r\n",
    "    def __len__(self):\r\n",
    "        return len(self.meta_data)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "#data argumentation\r\n",
    "size = (224,224)\r\n",
    "transform_train = transforms.Compose([\r\n",
    "    # transforms.RandomCrop(size=size, padding=(4,4,4,4), padding_mode='constant'),\r\n",
    "    transforms.RandomGrayscale(p=0.2),\r\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\r\n",
    "    transforms.RandomVerticalFlip(p=0.5),\r\n",
    "    transforms.RandomRotation(degrees=15),\r\n",
    "    transforms.RandomResizedCrop(size),\r\n",
    "    transforms.ToTensor()\r\n",
    "])\r\n",
    "\r\n",
    "transforms_test = transforms.Compose([\r\n",
    "    transforms.RandomResizedCrop(size),\r\n",
    "    transforms.ToTensor()\r\n",
    "])\r\n",
    "\r\n",
    "#make dataset\r\n",
    "# train_data = art_Dataset(train_df)\r\n",
    "test_data = art_Dataset(test_df, is_train=False)\r\n",
    "test_data.transform_test = transforms_test\r\n",
    "\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "import torch.autograd as autograd\r\n",
    "import torch.nn.functional as F\r\n",
    "from torchvision.models import resnet34\r\n",
    "from collections import defaultdict\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from tabulate import tabulate\r\n",
    "\r\n",
    "#train\r\n",
    "def train(\r\n",
    "    model: nn.Module,\r\n",
    "    optimizer: optim.Optimizer,\r\n",
    "    train_loader: torch.utils.data.DataLoader\r\n",
    ")-> pd.Series:\r\n",
    "\r\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "    model.train()\r\n",
    "    loss_function = nn.MSELoss()\r\n",
    "\r\n",
    "    metrics = defaultdict(float)\r\n",
    "    n_iters = len(train_loader)\r\n",
    "\r\n",
    "    for i, (x_i, y_i) in enumerate(train_loader):\r\n",
    "        x_i = x_i.to(device)\r\n",
    "        y_i = y_i.to(device).reshape(-1, 1).float()\r\n",
    "\r\n",
    "        pred = model(x_i)\r\n",
    "        loss = loss_function(pred, y_i)\r\n",
    "\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "        metric_i = {'loss': loss.item()}\r\n",
    "        for k, v in metric_i.items():\r\n",
    "            metrics[k] += v\r\n",
    "\r\n",
    "    for k, v in metrics.items():\r\n",
    "        metrics[k] /= n_iters\r\n",
    "\r\n",
    "    return pd.Series(metrics).add_prefix('train_')\r\n",
    "\r\n",
    "def predict(model: nn.Module, loader: torch.utils.data.DataLoader) -> np.ndarray:\r\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "    model.eval()\r\n",
    "\r\n",
    "    predicts = []\r\n",
    "    for x_i, y_i in loader:\r\n",
    "        with torch.no_grad():\r\n",
    "            pred = model(x_i.to(device))\r\n",
    "\r\n",
    "        predicts.extend(pred.data.cpu().numpy())\r\n",
    "\r\n",
    "    predict = np.array(predicts).reshape(-1)\r\n",
    "    return predict\r\n",
    "\r\n",
    "def cal_loss(y_test, y_pred) -> dict:\r\n",
    "    return {'rmse': mean_squared_error(y_test, y_pred) ** .5}\r\n",
    "\r\n",
    "def valid(\r\n",
    "    model: nn.Module,\r\n",
    "    valid_loader: torch.utils.data.DataLoader,\r\n",
    "    y_test: np.ndarray\r\n",
    ") -> pd.Series:\r\n",
    "\r\n",
    "    pred = predict(model, valid_loader)\r\n",
    "    loss = cal_loss(y_test, pred)\r\n",
    "\r\n",
    "    valid_score = pd.Series(loss)\r\n",
    "    return valid_score.add_prefix('valid_'), pred\r\n",
    "\r\n",
    "    \r\n",
    "#K fold\r\n",
    "def run_fold(\r\n",
    "    model: nn.Module,\r\n",
    "    train_df: pd.DataFrame,\r\n",
    "    valid_df: pd.DataFrame,\r\n",
    "    y_valid: np.ndarray,\r\n",
    "    output_dir: str,\r\n",
    "    n_epochs=30,\r\n",
    "    batchsize=64) -> np.ndarray:\r\n",
    "\r\n",
    "    os.makedirs(output_dir, exist_ok=True)\r\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\r\n",
    "\r\n",
    "    train_data = art_Dataset(train_df)\r\n",
    "    valid_data = art_Dataset(valid_df)\r\n",
    "    train_data.transform_train = transform_train\r\n",
    "    valid_data.transform_train = transform_train\r\n",
    "\r\n",
    "    train_loader = torch.utils.data.DataLoader(\r\n",
    "        train_data,\r\n",
    "        batch_size = batchsize,\r\n",
    "        shuffle=True\r\n",
    "    )\r\n",
    "    valid_loader = torch.utils.data.DataLoader(\r\n",
    "        valid_data,\r\n",
    "        batch_size=batchsize,\r\n",
    "        shuffle=True\r\n",
    "    )\r\n",
    "\r\n",
    "    loss_df = pd.DataFrame()\r\n",
    "    best_loss = np.inf\r\n",
    "    best_loss_key = 'valid_rmse'\r\n",
    "    valid_best_pred = None\r\n",
    "\r\n",
    "    for epoch in range(n_epochs):\r\n",
    "        train_loss = train(model, optimizer, train_loader)\r\n",
    "        valid_loss, valid_pred = valid(model, valid_loader, y_valid)\r\n",
    "\r\n",
    "        row = pd.concat([train_loss, valid_loss])\r\n",
    "        row['epoch'] = epoch\r\n",
    "        row = pd.DataFrame([row])\r\n",
    "        print(tabulate(row, headers=row.columns))\r\n",
    "        loss_df = pd.concat([loss_df, row], ignore_index=True)\r\n",
    "\r\n",
    "        current_loss = valid_loss[best_loss_key]\r\n",
    "\r\n",
    "        if current_loss < best_loss:\r\n",
    "            print(f'validation loss is improved {best_loss: .4f} -> {current_loss: .4f}')\r\n",
    "            torch.save(\r\n",
    "                model.state_dict(), os.path.join(output_dir, 'model_best.pth')\r\n",
    "            )\r\n",
    "            best_loss = current_loss\r\n",
    "            valid_best_pred = valid_pred\r\n",
    "\r\n",
    "    loss_df.to_csv(os.path.join(output_dir, 'loss.csc'), index=False)\r\n",
    "    return valid_best_pred\r\n",
    "\r\n",
    "def get_output_dir(output: str, n_cv: int):\r\n",
    "    return os.path.join(output, f'cv={n_cv}')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "from sklearn.model_selection import KFold\r\n",
    "oof = np.zeros((len(train_df),), dtype=np.float32)\r\n",
    "fold = KFold(n_splits=5, shuffle=True, random_state=0)\r\n",
    "cv = list(fold.split(X=train_df))\r\n",
    "OUTPUT = 'out_files/resnet32/sub02'\r\n",
    "\r\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n",
    "for i, (train_idx, valid_idx) in enumerate(cv):\r\n",
    "    print(f'-----------------{i: d} step-------------------')\r\n",
    "    output_csv = get_output_dir(OUTPUT, i)\r\n",
    "    model = resnet34(pretrained=False)\r\n",
    "    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\r\n",
    "\r\n",
    "    model.to(device)\r\n",
    "\r\n",
    "    oof_i = run_fold(\r\n",
    "        model,\r\n",
    "        train_df.iloc[train_idx],\r\n",
    "        train_df.iloc[valid_idx],\r\n",
    "        train_df['sorting_date'].values[valid_idx],\r\n",
    "        output_csv,\r\n",
    "        n_epochs=30\r\n",
    "    )\r\n",
    "\r\n",
    "    oof[valid_idx] = oof_i\r\n",
    "    break\r\n",
    "\r\n",
    "print('finish')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "----------------- 0 step-------------------\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0    2.9313e+06       1681.44        0\n",
      "validation loss is improved  inf ->  1681.4361\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0   2.72185e+06       1602.77        1\n",
      "validation loss is improved  1681.4361 ->  1602.7727\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0   2.42665e+06       1510.25        2\n",
      "validation loss is improved  1602.7727 ->  1510.2509\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0   2.10299e+06       1384.11        3\n",
      "validation loss is improved  1510.2509 ->  1384.1073\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0   1.75442e+06       1250.68        4\n",
      "validation loss is improved  1384.1073 ->  1250.6838\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0   1.38827e+06       1095.49        5\n",
      "validation loss is improved  1250.6838 ->  1095.4897\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0   1.05164e+06       942.004        6\n",
      "validation loss is improved  1095.4897 ->  942.0043\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0        754921       793.095        7\n",
      "validation loss is improved  942.0043 ->  793.0951\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0        511906       631.156        8\n",
      "validation loss is improved  793.0951 ->  631.1562\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0        324229       477.373        9\n",
      "validation loss is improved  631.1562 ->  477.3734\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0        194042       372.674       10\n",
      "validation loss is improved  477.3734 ->  372.6740\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0        110009       268.717       11\n",
      "validation loss is improved  372.6740 ->  268.7166\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       60236.3       189.064       12\n",
      "validation loss is improved  268.7166 ->  189.0640\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       32740.6       159.326       13\n",
      "validation loss is improved  189.0640 ->  159.3265\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       19398.9       114.066       14\n",
      "validation loss is improved  159.3265 ->  114.0661\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       12990.4        119.43       15\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       10324.5       139.303       16\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       9035.11       110.359       17\n",
      "validation loss is improved  114.0661 ->  110.3594\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       8647.95       108.545       18\n",
      "validation loss is improved  110.3594 ->  108.5448\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       8450.57       137.494       19\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       8302.89       114.808       20\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       8270.49       110.616       21\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       8825.97       109.041       22\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       8205.95       115.122       23\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       8232.12       116.087       24\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       8259.28       105.975       25\n",
      "validation loss is improved  108.5448 ->  105.9747\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0        8187.1       109.165       26\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       8016.86       111.263       27\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       7976.09       141.477       28\n",
      "      train_loss    valid_rmse    epoch\n",
      "--  ------------  ------------  -------\n",
      " 0       7964.45       119.167       29\n",
      "finish\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size = 128)\r\n",
    "\r\n",
    "test_pred = []\r\n",
    "\r\n",
    "for i in range(len(cv)):\r\n",
    "    get_model_dir = get_output_dir(OUTPUT, i)\r\n",
    "    model_path = os.path.join(get_model_dir, 'model_best.pth')\r\n",
    "    model = resnet34(pretrained=False)\r\n",
    "    model.fc = nn.Linear(in_features=512, out_features=1, bias=True)\r\n",
    "\r\n",
    "    model.load_state_dict(torch.load(model_path))\r\n",
    "\r\n",
    "    model.to(device)\r\n",
    "\r\n",
    "    y_pred = predict(model, loader=test_loader)\r\n",
    "\r\n",
    "    test_pred.append(y_pred)\r\n",
    "\r\n",
    "model_pred = np.array(test_pred).mean(axis=0)\r\n",
    "model_pred"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([1707.342 , 1739.2659, 1744.2054, ..., 1749.5671, 1737.3004,\n",
       "       1728.0544], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "for pred in model_pred:\r\n",
    "    if 2000>=pred >=1801 :\r\n",
    "        print(pred)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "pd.DataFrame({\r\n",
    "    'target': model_pred\r\n",
    "}).to_csv(os.path.join(OUTPUT, 'sub01.csv'), index=False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}